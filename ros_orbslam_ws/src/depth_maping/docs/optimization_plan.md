# ç³»ç»Ÿæ€§èƒ½ä¼˜åŒ–è®¡åˆ’

**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv1.0  
**åˆ›å»ºæ—¥æœŸ**ï¼š2026-01-15  
**çŠ¶æ€**ï¼šå¾…å®æ–½

---

## ğŸ“Š å½“å‰æ€§èƒ½åˆ†æ

### æ€§èƒ½ç“¶é¢ˆè¯†åˆ«

| æ¨¡å— | è€—æ—¶ï¼ˆä¼°ç®—ï¼‰ | å æ¯” | ä¼˜å…ˆçº§ |
|------|-------------|------|--------|
| æ·±åº¦ä¼°è®¡ | ~0.3s/å¸§ | 33% | â­â­â­â­â­ |
| ç‚¹äº‘å¤„ç† | ~0.2s/å¸§ | 22% | â­â­â­â­ |
| å¯è§†åŒ– | ~0.1s/å¸§ | 11% | â­â­â­ |
| 2Dåœ°å›¾ç”Ÿæˆ | ~0.05s/10å¸§ | 6% | â­â­ |
| å…¶ä»–å¼€é”€ | ~0.25s/å¸§ | 28% | â­â­â­ |
| **æ€»è®¡** | **~0.9s/å¸§** | **100%** | **1.1 FPS** |

### å½“å‰é…ç½®
- **æ·±åº¦ä¼°è®¡åˆ†è¾¨ç‡**ï¼š256px
- **ä½“ç´ ä¸‹é‡‡æ ·**ï¼š1.0m
- **æ»‘åŠ¨çª—å£**ï¼š3å¸§
- **2Dåœ°å›¾æ›´æ–°**ï¼šæ¯10å¸§
- **ç‚¹äº‘å‘å¸ƒ**ï¼šæ¯å¸§

---

## ğŸš€ ä¼˜åŒ–æ–¹æ¡ˆ

### ä¼˜å…ˆçº§1ï¼šæ·±åº¦ä¼°è®¡åŠ é€Ÿ â­â­â­â­â­

#### æ–¹æ¡ˆ1.1ï¼šTensorRT åŠ é€Ÿ
**é¢„æœŸæ•ˆæœ**ï¼š2-5å€åŠ é€Ÿï¼ˆ0.3s â†’ 0.06-0.15sï¼‰

**å®æ–½æ­¥éª¤**ï¼š
1. å¯¼å‡º ONNX æ¨¡å‹
   ```python
   import torch
   model = DepthAnythingV2(...)
   dummy_input = torch.randn(1, 3, 256, 256)
   torch.onnx.export(model, dummy_input, "depth_anything_v2.onnx")
   ```

2. è½¬æ¢ä¸º TensorRT engine
   ```bash
   trtexec --onnx=depth_anything_v2.onnx \
           --saveEngine=depth_anything_v2.trt \
           --fp16  # ä½¿ç”¨FP16åŠ é€Ÿ
   ```

3. é›†æˆåˆ°ä»£ç 
   ```python
   import tensorrt as trt
   import pycuda.driver as cuda
   
   class TensorRTDepthEstimator:
       def __init__(self, engine_path):
           self.engine = self.load_engine(engine_path)
           self.context = self.engine.create_execution_context()
   ```

**ä¼˜ç‚¹**ï¼š
- æ˜¾è‘—æå‡é€Ÿåº¦
- é™ä½GPUå ç”¨
- æ”¯æŒFP16/INT8é‡åŒ–

**ç¼ºç‚¹**ï¼š
- éœ€è¦NVIDIA GPU
- é¦–æ¬¡è½¬æ¢è€—æ—¶ï¼ˆ~5-10åˆ†é’Ÿï¼‰
- æ¨¡å‹å›ºå®šè¾“å…¥å°ºå¯¸

**å‚è€ƒèµ„æº**ï¼š
- TensorRTå®˜æ–¹æ–‡æ¡£ï¼šhttps://docs.nvidia.com/deeplearning/tensorrt/
- PyTorch to TensorRTï¼šhttps://github.com/NVIDIA-AI-IOT/torch2trt

---

#### æ–¹æ¡ˆ1.2ï¼šæ¨¡å‹é‡åŒ–
**é¢„æœŸæ•ˆæœ**ï¼š1.5-2å€åŠ é€Ÿï¼ˆ0.3s â†’ 0.15-0.2sï¼‰

**å®æ–½æ­¥éª¤**ï¼š
```python
# FP32 â†’ FP16
model = model.half()  # è½¬æ¢ä¸ºFP16
input_tensor = input_tensor.half()

# æˆ–ä½¿ç”¨ torch.cuda.amp è‡ªåŠ¨æ··åˆç²¾åº¦
from torch.cuda.amp import autocast

with autocast():
    depth = model(image)
```

**ä¼˜ç‚¹**ï¼š
- å®æ–½ç®€å•
- ç²¾åº¦æŸå¤±å¾ˆå°ï¼ˆ<1%ï¼‰
- å†…å­˜å ç”¨å‡åŠ

**ç¼ºç‚¹**ï¼š
- éœ€è¦GPUæ”¯æŒFP16
- æŸäº›æ“ä½œå¯èƒ½ä¸æ”¯æŒ

---

#### æ–¹æ¡ˆ1.3ï¼šé™ä½è¾“å…¥åˆ†è¾¨ç‡
**å½“å‰**ï¼š256px  
**å¯é€‰**ï¼š192px, 384px

**æƒè¡¡åˆ†æ**ï¼š
| åˆ†è¾¨ç‡ | é€Ÿåº¦ | ç²¾åº¦ | æ¨èåœºæ™¯ |
|--------|------|------|----------|
| 192px | å¿«1.5å€ | ç•¥é™ | å®æ—¶æ€§è¦æ±‚é«˜ |
| 256px | åŸºå‡† | å¹³è¡¡ | å½“å‰è®¾ç½® |
| 384px | æ…¢2å€ | æ›´é«˜ | ç²¾åº¦è¦æ±‚é«˜ |

---

### ä¼˜å…ˆçº§2ï¼šå¹¶è¡Œå¤„ç† â­â­â­â­â­

#### æ–¹æ¡ˆ2.1ï¼šå¤šçº¿ç¨‹å¤„ç†
**é¢„æœŸæ•ˆæœ**ï¼šæ•´ä½“æé€Ÿ30-50%

**æ¶æ„è®¾è®¡**ï¼š
```python
import threading
from queue import Queue

class ParallelMappingPipeline:
    def __init__(self):
        self.depth_queue = Queue(maxsize=2)
        self.pointcloud_queue = Queue(maxsize=2)
        
        # å¯åŠ¨å·¥ä½œçº¿ç¨‹
        self.depth_thread = threading.Thread(target=self.depth_worker)
        self.pointcloud_thread = threading.Thread(target=self.pointcloud_worker)
        self.map_thread = threading.Thread(target=self.map_worker)
        
    def depth_worker(self):
        """æ·±åº¦ä¼°è®¡çº¿ç¨‹"""
        while True:
            image = self.depth_queue.get()
            depth = self.depth_estimator.estimate(image)
            self.pointcloud_queue.put((image, depth))
            
    def pointcloud_worker(self):
        """ç‚¹äº‘ç”Ÿæˆçº¿ç¨‹"""
        while True:
            image, depth = self.pointcloud_queue.get()
            points = self.generate_pointcloud(depth, image)
            self.map_queue.put(points)
            
    def map_worker(self):
        """åœ°å›¾æ›´æ–°çº¿ç¨‹"""
        while True:
            points = self.map_queue.get()
            self.map_builder.update(points)
```

**æ³¨æ„äº‹é¡¹**ï¼š
- ä½¿ç”¨çº¿ç¨‹å®‰å…¨çš„æ•°æ®ç»“æ„
- æ§åˆ¶é˜Ÿåˆ—å¤§å°é¿å…å†…å­˜æº¢å‡º
- å¤„ç†çº¿ç¨‹åŒæ­¥å’Œå¼‚å¸¸

---

#### æ–¹æ¡ˆ2.2ï¼šGPUåŠ é€Ÿç‚¹äº‘å¤„ç†
**é¢„æœŸæ•ˆæœ**ï¼šç‚¹äº‘å¤„ç†åŠ é€Ÿ5-10å€

**å®æ–½æ–¹æ¡ˆ**ï¼š
```python
import torch

class GPUPointCloudGenerator:
    def generate(self, depth, rgb, camera_params, pose):
        # ä¿æŒæ•°æ®åœ¨GPUä¸Š
        depth_gpu = torch.from_numpy(depth).cuda()
        
        # GPUä¸Šè¿›è¡Œåæ ‡å˜æ¢
        h, w = depth_gpu.shape
        u, v = torch.meshgrid(torch.arange(w), torch.arange(h))
        u, v = u.cuda(), v.cuda()
        
        # è®¡ç®—3Dåæ ‡
        Z = depth_gpu
        X = (u - cx) * Z / fx
        Y = (v - cy) * Z / fy
        
        points = torch.stack([X, Y, Z], dim=-1)
        
        # ä½å§¿å˜æ¢ï¼ˆGPUï¼‰
        pose_gpu = torch.from_numpy(pose).cuda()
        points_world = points @ pose_gpu[:3, :3].T + pose_gpu[:3, 3]
        
        # æœ€åå†è½¬å›CPU
        return points_world.cpu().numpy()
```

**ä¼˜ç‚¹**ï¼š
- é¿å…CPU-GPUæ•°æ®ä¼ è¾“
- å……åˆ†åˆ©ç”¨GPUå¹¶è¡Œè®¡ç®—
- ä¸æ·±åº¦ä¼°è®¡å…±äº«GPU

---

### ä¼˜å…ˆçº§3ï¼šå†…å­˜ä¼˜åŒ– â­â­â­â­

#### æ–¹æ¡ˆ3.1ï¼šç‚¹äº‘å†…å­˜ç®¡ç†
**é—®é¢˜**ï¼šæ»‘åŠ¨çª—å£ç´¯ç§¯å¯¼è‡´å†…å­˜æŒç»­å¢é•¿

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
class MemoryManagedPointCloud:
    def __init__(self, max_points=1_000_000):
        self.max_points = max_points
        self.points = []
        self.colors = []
        
    def add_points(self, new_points, new_colors):
        self.points.append(new_points)
        self.colors.append(new_colors)
        
        # æ£€æŸ¥æ€»ç‚¹æ•°
        total_points = sum(len(p) for p in self.points)
        
        if total_points > self.max_points:
            # ç­–ç•¥1ï¼šç§»é™¤æœ€æ—§çš„å¸§
            self.points.pop(0)
            self.colors.pop(0)
            
            # ç­–ç•¥2ï¼šéšæœºä¸‹é‡‡æ ·
            # all_points = np.vstack(self.points)
            # indices = np.random.choice(len(all_points), self.max_points)
            # self.points = [all_points[indices]]
```

**é…ç½®å‚æ•°**ï¼š
```yaml
memory_management:
  max_points: 1000000  # 100ä¸‡ç‚¹ä¸Šé™
  strategy: "remove_oldest"  # æˆ– "random_sample"
  warning_threshold: 0.8  # 80%æ—¶è­¦å‘Š
```

---

#### æ–¹æ¡ˆ3.2ï¼šæŒ‰éœ€ç”Ÿæˆ2Dåœ°å›¾
**å½“å‰**ï¼šæ¯10å¸§ç”Ÿæˆä¸€æ¬¡  
**ä¼˜åŒ–**ï¼šä»…åœ¨éœ€è¦æ—¶ç”Ÿæˆ

**å®æ–½**ï¼š
```python
class OnDemandMapBuilder:
    def __init__(self):
        self.map_dirty = False
        self.cached_map = None
        
    def update_points(self, points):
        self.points = points
        self.map_dirty = True  # æ ‡è®°åœ°å›¾éœ€è¦æ›´æ–°
        
    def get_map(self):
        if self.map_dirty:
            self.cached_map = self.generate_map()
            self.map_dirty = False
        return self.cached_map
```

---

### ä¼˜å…ˆçº§4ï¼šç®—æ³•ä¼˜åŒ– â­â­â­â­

#### æ–¹æ¡ˆ4.1ï¼šå¢é‡å¼2Dåœ°å›¾æ›´æ–°
**é¢„æœŸæ•ˆæœ**ï¼š2Dåœ°å›¾ç”ŸæˆåŠ é€Ÿ5-10å€

**å½“å‰é—®é¢˜**ï¼šæ¯æ¬¡é‡æ–°è®¡ç®—æ•´ä¸ªåœ°å›¾

**ä¼˜åŒ–æ–¹æ¡ˆ**ï¼š
```python
class IncrementalOccupancyMap:
    def __init__(self, resolution):
        self.resolution = resolution
        self.grid_counts = {}  # ä½¿ç”¨å­—å…¸å­˜å‚¨éé›¶ç½‘æ ¼
        
    def update(self, new_points):
        """åªæ›´æ–°æ–°ç‚¹å½±å“çš„ç½‘æ ¼"""
        # è®¡ç®—æ–°ç‚¹æ‰€åœ¨çš„ç½‘æ ¼
        grid_indices = (new_points / self.resolution).astype(int)
        
        # æ›´æ–°è®¡æ•°
        for idx in grid_indices:
            key = tuple(idx)
            self.grid_counts[key] = self.grid_counts.get(key, 0) + 1
            
    def get_map(self):
        """ä»å­—å…¸å¿«é€Ÿç”Ÿæˆåœ°å›¾"""
        # åªå¤„ç†æœ‰ç‚¹çš„ç½‘æ ¼
        occupied_cells = {k: v for k, v in self.grid_counts.items() 
                         if v >= self.occupied_thresh}
        return self.dict_to_grid(occupied_cells)
```

**ä¼˜ç‚¹**ï¼š
- é¿å…é‡å¤è®¡ç®—
- å†…å­˜æ•ˆç‡é«˜ï¼ˆç¨€ç–å­˜å‚¨ï¼‰
- æ”¯æŒå¤§èŒƒå›´åœ°å›¾

---

#### æ–¹æ¡ˆ4.2ï¼šè‡ªé€‚åº”ä½“ç´ ä¸‹é‡‡æ ·
**å½“å‰**ï¼šå›ºå®š voxel_size=1.0  
**ä¼˜åŒ–**ï¼šæ ¹æ®ç‚¹äº‘å¯†åº¦åŠ¨æ€è°ƒæ•´

**å®æ–½**ï¼š
```python
def adaptive_voxel_size(points, target_points=50000):
    """
    æ ¹æ®ç‚¹äº‘æ•°é‡è‡ªåŠ¨è°ƒæ•´ä½“ç´ å¤§å°
    
    Args:
        points: è¾“å…¥ç‚¹äº‘
        target_points: ç›®æ ‡ç‚¹äº‘æ•°é‡
        
    Returns:
        optimal_voxel_size: æœ€ä¼˜ä½“ç´ å¤§å°
    """
    current_points = len(points)
    
    if current_points < target_points:
        return 0.5  # ç‚¹å°‘ï¼Œç”¨å°voxelä¿ç•™ç»†èŠ‚
    elif current_points < target_points * 2:
        return 1.0  # é€‚ä¸­
    else:
        # è®¡ç®—éœ€è¦çš„voxelå¤§å°
        ratio = current_points / target_points
        return 1.0 * (ratio ** (1/3))  # ç«‹æ–¹æ ¹å…³ç³»
```

**é…ç½®**ï¼š
```yaml
adaptive_downsampling:
  enabled: true
  target_points: 50000
  min_voxel_size: 0.5
  max_voxel_size: 2.0
```

---

### ä¼˜å…ˆçº§5ï¼šä¼ è¾“ä¼˜åŒ– â­â­â­

#### æ–¹æ¡ˆ5.1ï¼šç‚¹äº‘å‹ç¼©
**é¢„æœŸæ•ˆæœ**ï¼šå‡å°‘ç½‘ç»œå¸¦å®½50-80%

**æ–¹æ¡ˆAï¼šä½¿ç”¨ROSå‹ç¼©ä¼ è¾“**
```python
# ä½¿ç”¨ compressed_depth_image_transport
from sensor_msgs.msg import CompressedImage

compressed_msg = CompressedImage()
compressed_msg.format = "png"
compressed_msg.data = cv2.imencode('.png', depth_image)[1].tobytes()
```

**æ–¹æ¡ˆBï¼šè‡ªå®šä¹‰å‹ç¼©**
```python
import zlib

def compress_pointcloud(points, colors):
    """å‹ç¼©ç‚¹äº‘æ•°æ®"""
    # é‡åŒ–åæ ‡ï¼ˆfloat32 â†’ int16ï¼‰
    points_quantized = (points * 1000).astype(np.int16)
    colors_quantized = (colors * 255).astype(np.uint8)
    
    # å‹ç¼©
    points_compressed = zlib.compress(points_quantized.tobytes())
    colors_compressed = zlib.compress(colors_quantized.tobytes())
    
    return points_compressed, colors_compressed
```

---

#### æ–¹æ¡ˆ5.2ï¼šé™ä½å‘å¸ƒé¢‘ç‡
**å½“å‰é…ç½®**ï¼š
- ç‚¹äº‘ï¼šæ¯å¸§å‘å¸ƒ
- 2Dåœ°å›¾ï¼šæ¯10å¸§å‘å¸ƒ

**ä¼˜åŒ–é…ç½®**ï¼š
```yaml
publish_rate:
  point_cloud: 2  # æ¯2å¸§å‘å¸ƒä¸€æ¬¡
  occupancy_grid: 30  # æ¯30å¸§å‘å¸ƒä¸€æ¬¡
  depth_image: 5  # æ¯5å¸§å‘å¸ƒä¸€æ¬¡ï¼ˆå¦‚æœéœ€è¦ï¼‰
```

**å®æ–½**ï¼š
```python
if self.frame_counter % self.point_cloud_publish_rate == 0:
    self.pcl_pub.publish(point_cloud_msg)
    
if self.frame_counter % self.map_publish_rate == 0:
    self.map_pub.publish(occupancy_grid_msg)
```

---

## ğŸ“ˆ é¢„æœŸæ€§èƒ½æå‡

### é˜¶æ®µæ€§ç›®æ ‡

#### é˜¶æ®µ1ï¼šå¿«é€Ÿä¼˜åŒ–ï¼ˆ1-2å¤©ï¼‰âš¡
**å®æ–½å†…å®¹**ï¼š
- âœ… ç¦ç”¨Open3Då¯è§†åŒ–ï¼ˆå·²å®Œæˆï¼‰
- é™ä½2Dåœ°å›¾æ›´æ–°é¢‘ç‡ï¼ˆ10â†’30å¸§ï¼‰
- è°ƒæ•´ç‚¹äº‘å‘å¸ƒé¢‘ç‡ï¼ˆæ¯å¸§â†’æ¯2å¸§ï¼‰
- å¢åŠ ä½“ç´ ä¸‹é‡‡æ ·ï¼ˆ1.0â†’1.5ï¼‰

**é¢„æœŸæ•ˆæœ**ï¼š
```
å½“å‰ï¼š1.1 FPS
ä¼˜åŒ–åï¼š2.0 FPS
æå‡ï¼š82%
```

---

#### é˜¶æ®µ2ï¼šä¸­æœŸä¼˜åŒ–ï¼ˆ3-5å¤©ï¼‰ğŸš€
**å®æ–½å†…å®¹**ï¼š
- å®æ–½å¤šçº¿ç¨‹å¤„ç†
- GPUåŠ é€Ÿç‚¹äº‘å¤„ç†
- å¢é‡å¼2Dåœ°å›¾æ›´æ–°
- å†…å­˜ç®¡ç†ä¼˜åŒ–

**é¢„æœŸæ•ˆæœ**ï¼š
```
å½“å‰ï¼š2.0 FPS
ä¼˜åŒ–åï¼š4.0 FPS
æå‡ï¼š100%
```

---

#### é˜¶æ®µ3ï¼šæ·±åº¦ä¼˜åŒ–ï¼ˆ1-2å‘¨ï¼‰ğŸ”¥
**å®æ–½å†…å®¹**ï¼š
- TensorRTåŠ é€Ÿæ·±åº¦ä¼°è®¡
- æ¨¡å‹é‡åŒ–ï¼ˆFP16ï¼‰
- ç‚¹äº‘å‹ç¼©ä¼ è¾“
- è‡ªé€‚åº”å‚æ•°è°ƒæ•´

**é¢„æœŸæ•ˆæœ**ï¼š
```
å½“å‰ï¼š4.0 FPS
ä¼˜åŒ–åï¼š8-10 FPS
æå‡ï¼š100-150%
```

---

### æœ€ç»ˆæ€§èƒ½é¢„æµ‹

| æ¨¡å— | å½“å‰è€—æ—¶ | ä¼˜åŒ–åè€—æ—¶ | æå‡ |
|------|---------|-----------|------|
| æ·±åº¦ä¼°è®¡ | 0.3s | 0.06s | 5x |
| ç‚¹äº‘å¤„ç† | 0.2s | 0.04s | 5x |
| å¯è§†åŒ– | 0.1s | 0.0s | âˆ |
| 2Dåœ°å›¾ | 0.05s | 0.01s | 5x |
| å…¶ä»– | 0.25s | 0.14s | 1.8x |
| å¹¶è¡ŒèŠ‚çœ | - | -0.1s | - |
| **æ€»è®¡** | **0.9s** | **0.15s** | **6x** |
| **FPS** | **1.1** | **6.7** | **6x** |

---

## ğŸ› ï¸ å®æ–½ä¼˜å…ˆçº§å»ºè®®

### å¦‚æœè¿½æ±‚å¿«é€Ÿè§æ•ˆ
1. é˜¶æ®µ1å¿«é€Ÿä¼˜åŒ–
2. å¤šçº¿ç¨‹å¤„ç†
3. é™ä½å‘å¸ƒé¢‘ç‡

**æ—¶é—´**ï¼š2-3å¤©  
**æ•ˆæœ**ï¼š1.1 FPS â†’ 3 FPS

---

### å¦‚æœè¿½æ±‚æœ€ä½³æ€§èƒ½
1. å®Œæ•´å®æ–½é˜¶æ®µ1-3
2. TensorRTåŠ é€Ÿ
3. GPUåŠ é€Ÿç‚¹äº‘

**æ—¶é—´**ï¼š2-3å‘¨  
**æ•ˆæœ**ï¼š1.1 FPS â†’ 8-10 FPS

---

### å¦‚æœç¡¬ä»¶å—é™ï¼ˆæ— GPUï¼‰
1. ç®—æ³•ä¼˜åŒ–ï¼ˆå¢é‡æ›´æ–°ï¼‰
2. è‡ªé€‚åº”é‡‡æ ·
3. é™ä½åˆ†è¾¨ç‡

**æ—¶é—´**ï¼š1å‘¨  
**æ•ˆæœ**ï¼š1.1 FPS â†’ 2-3 FPS

---

## ğŸ“ å®æ–½æ£€æŸ¥æ¸…å•

### å‡†å¤‡å·¥ä½œ
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•ï¼ˆè®°å½•å½“å‰FPSï¼‰
- [ ] ç¡®è®¤ç¡¬ä»¶é…ç½®ï¼ˆGPUå‹å·ã€å†…å­˜ï¼‰
- [ ] å¤‡ä»½å½“å‰ä»£ç 
- [ ] åˆ›å»ºæ€§èƒ½æµ‹è¯•è„šæœ¬

### é˜¶æ®µ1
- [ ] ç¦ç”¨å¯è§†åŒ–
- [ ] è°ƒæ•´å‘å¸ƒé¢‘ç‡
- [ ] å¢åŠ ä½“ç´ å¤§å°
- [ ] æ€§èƒ½æµ‹è¯•

### é˜¶æ®µ2
- [ ] å®ç°å¤šçº¿ç¨‹æ¡†æ¶
- [ ] GPUç‚¹äº‘å¤„ç†
- [ ] å¢é‡åœ°å›¾æ›´æ–°
- [ ] å†…å­˜ç®¡ç†
- [ ] æ€§èƒ½æµ‹è¯•

### é˜¶æ®µ3
- [ ] TensorRTæ¨¡å‹è½¬æ¢
- [ ] é›†æˆTensorRTæ¨ç†
- [ ] FP16é‡åŒ–
- [ ] ç‚¹äº‘å‹ç¼©
- [ ] æœ€ç»ˆæ€§èƒ½æµ‹è¯•

---

## ğŸ” æ€§èƒ½ç›‘æ§

### ç›‘æ§æŒ‡æ ‡
```python
class PerformanceMonitor:
    def __init__(self):
        self.metrics = {
            'depth_estimation_time': [],
            'pointcloud_generation_time': [],
            'map_update_time': [],
            'total_callback_time': [],
            'memory_usage': [],
            'fps': []
        }
        
    def log_metrics(self):
        """è®°å½•æ€§èƒ½æŒ‡æ ‡"""
        rospy.loginfo_throttle(10, f"""
        æ€§èƒ½ç»Ÿè®¡ï¼ˆæœ€è¿‘100å¸§ï¼‰:
        - æ·±åº¦ä¼°è®¡: {np.mean(self.metrics['depth_estimation_time']):.3f}s
        - ç‚¹äº‘ç”Ÿæˆ: {np.mean(self.metrics['pointcloud_generation_time']):.3f}s
        - åœ°å›¾æ›´æ–°: {np.mean(self.metrics['map_update_time']):.3f}s
        - æ€»è€—æ—¶: {np.mean(self.metrics['total_callback_time']):.3f}s
        - FPS: {1/np.mean(self.metrics['total_callback_time']):.1f}
        - å†…å­˜: {self.get_memory_usage():.1f} MB
        """)
```

---

## ğŸ“š å‚è€ƒèµ„æº

### TensorRT
- å®˜æ–¹æ–‡æ¡£ï¼šhttps://docs.nvidia.com/deeplearning/tensorrt/
- PyTorchè½¬æ¢ï¼šhttps://github.com/NVIDIA-AI-IOT/torch2trt
- ç¤ºä¾‹ä»£ç ï¼šhttps://github.com/NVIDIA/TensorRT/tree/main/samples/python

### å¹¶è¡Œå¤„ç†
- Python threadingï¼šhttps://docs.python.org/3/library/threading.html
- Python multiprocessingï¼šhttps://docs.python.org/3/library/multiprocessing.html
- ROSå¤šçº¿ç¨‹ï¼šhttp://wiki.ros.org/rospy/Overview/Publishers%20and%20Subscribers

### ç‚¹äº‘å¤„ç†
- Open3Dæ–‡æ¡£ï¼šhttp://www.open3d.org/docs/
- PCLæ•™ç¨‹ï¼šhttps://pcl.readthedocs.io/
- GPUåŠ é€Ÿï¼šhttps://github.com/NVIDIA/cuda-samples

---

## ğŸ“… æ›´æ–°æ—¥å¿—

| æ—¥æœŸ | ç‰ˆæœ¬ | æ›´æ–°å†…å®¹ |
|------|------|----------|
| 2026-01-15 | v1.0 | åˆå§‹ç‰ˆæœ¬ï¼Œå®Œæ•´ä¼˜åŒ–æ–¹æ¡ˆ |

---

**æ³¨æ„**ï¼šæœ¬æ–‡æ¡£ä¸ºä¼˜åŒ–è®¡åˆ’ï¼Œå®é™…å®æ–½æ—¶éœ€è¦æ ¹æ®å…·ä½“æƒ…å†µè°ƒæ•´ã€‚å»ºè®®å…ˆè¿›è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•ï¼Œç„¶åé€æ­¥å®æ–½ä¼˜åŒ–æ–¹æ¡ˆã€‚